{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import the following libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from numpy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#copying the files in the following path(data) to the list(lst)\n",
    "data = \"C:\\\\Users\\\\saich\\\\Desktop\\\\Face_Recognition\\\\YaleFaceDatabase\\\\\"\n",
    "lst = np.array(os.listdir(data))\n",
    "images=[]\n",
    "#Flattening the image and converting them to ndarray\n",
    "for i in lst:\n",
    "    img=Image.open('Face_Recognition/YaleFaceDatabase/'+i).convert('L')\n",
    "    img=np.array(img,'uint8')\n",
    "    img = img.flatten()\n",
    "    img=list(img)\n",
    "    images.append(img)\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_img = []\n",
    "test_img=[]\n",
    "# I have used the Yale dataset. It has images of 15 persons 11 images each with different emotions.\n",
    "#I have taken first 8 images for training and next 3 images for testing for all the 15 persons\n",
    "for i in range(len(images)):\n",
    "    if i%11>=8:\n",
    "        test_img.append(images[i,:])\n",
    "    else:\n",
    "        train_img.append(images[i,:])\n",
    "        # print(train_img[0])\n",
    "#Converting the list to ndarray\n",
    "test_img = np.array(test_img)\n",
    "train_img = np.array(train_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculating the average image\n",
    "avgimg = train_img.mean(axis = 0)\n",
    "#image matrix after subtracting mean image\n",
    "phi_transpose = np.subtract(train_img,avgimg)\n",
    "phi = phi_transpose.transpose()\n",
    "#C is the covariance matrix\n",
    "c = np.matmul(phi_transpose,phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculating the eigen values and eigen vectors of the covariance matrix (A.T)A\n",
    "eigval,eigvec = linalg.eigh(c)\n",
    "#Adding all the eigen values\n",
    "eigval_sum = eigval.sum()\n",
    "findk = 0\n",
    "eigval_rev = eigval[::-1]\n",
    "#eigvec_rev = eigvec[::-1]\n",
    "for i in range(120):\n",
    "    findk = (eigval_rev[i])/eigval_sum + findk\n",
    "    if findk>=0.9:\n",
    "        k = i\n",
    "        break\n",
    "#Let us take the top k eigen vectors of the corresponding eigen values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e=np.array(eigvec).transpose()\n",
    "eigvec_rev=e[::-1]\n",
    "k_eigvec = eigvec_rev[:k, :]\n",
    "#Calculating the eigan vectors of the actual matrix AA.T\n",
    "real_eigvec_beforenorm = np.dot(phi,k_eigvec.T)\n",
    "#normalizing the eigen vectors\n",
    "real_eigvec = np.divide(real_eigvec_beforenorm,linalg.norm(real_eigvec_beforenorm))\n",
    "train_weights = []\n",
    "#Calculating the weights of the training set\n",
    "for vector in phi_transpose:\n",
    "    train_weights.append(np.dot(real_eigvec.T, vector))\n",
    "train_weights=np.array(train_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Normalize the test set by subtracting mean from test set\n",
    "test_normalized = np.subtract(test_img,avgimg)\n",
    "test_norm = test_normalized.transpose()\n",
    "test_weights = np.matmul(real_eigvec.T,test_norm)\n",
    "#Calculating the error\n",
    "#Here i have used Euclidian norm as error function\n",
    "#it has been reported that the Mahalanobis distance performs better:\n",
    "w=0\n",
    "for i in range(45):\n",
    "    test_weight=test_weights[:, i]\n",
    "    loss=[]\n",
    "    for j in range(120):\n",
    "        weight=train_weights[j]\n",
    "        loss.append(linalg.norm(test_weight-weight, 2))\n",
    "    min_loss=min(loss)\n",
    "    min_index=loss.index(min_loss)\n",
    "    if (min_index//8) == (i//3):\n",
    "        w=w+1\n",
    "test_accuracy = w/45\n",
    "#Accuracy of the test set\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
